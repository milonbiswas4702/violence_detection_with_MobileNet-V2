{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PrSQewh4hN1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f268413-38f6-430c-81f3-4b0aa308367c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import platform\n",
        "from IPython.display import clear_output\n",
        "print(platform.platform())\n",
        "\n",
        "def resolve_dir(Dir):\n",
        "    if not os.path.exists(Dir):\n",
        "        os.mkdir(Dir)\n",
        "\n",
        "def reset_path(Dir):\n",
        "    if not os.path.exists(Dir):\n",
        "        os.mkdir(Dir)\n",
        "    else:\n",
        "        os.system('rm -f {}/*'.format( Dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOSuH5Yv4mFX",
        "outputId": "9d3dafa5-55dd-4019-9b51-9d5937c2677a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: nvidia-smi: command not found\n",
            "Tensorflow version 2.7.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.random.set_seed(73)\n",
        "TPU_INIT = False\n",
        "\n",
        "if TPU_INIT:\n",
        "    try:\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
        "        tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "    \n",
        "    except ValueError:\n",
        "        raise BaseException('ERROR: Not connected to a TPU runtime!')\n",
        "else:\n",
        "    !nvidia-smi;    \n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdcQ8YUF40WH",
        "outputId": "01bdc754-dd8d-4476-c30c-3229b540b080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real_Life_Violence_Dataset\n"
          ]
        }
      ],
      "source": [
        "MyDrive = '/content/drive/MyDrive'\n",
        "\n",
        "PROJECT_DIR = '../content/drive/MyDrive/Violence_Detection/Violence'\n",
        "!ls {PROJECT_DIR}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DuWBFNYx5Hgx"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import imageio\n",
        "import imgaug.augmenters as iaa\n",
        "import imgaug as ia\n",
        "\n",
        "IMG_SIZE = 128\n",
        "ColorChannels = 3\n",
        "\n",
        "def video_to_frames(video):\n",
        "    vidcap = cv2.VideoCapture(video)\n",
        "    \n",
        "    import math\n",
        "    rate = math.floor(vidcap.get(3))\n",
        "    count = 0\n",
        "    \n",
        "    ImageFrames = []\n",
        "    while vidcap.isOpened():\n",
        "        ID = vidcap.get(1)\n",
        "        success, image = vidcap.read()\n",
        "        \n",
        "        if success:\n",
        "            # skipping frames to avoid duplications \n",
        "            if (ID % 7 == 0):\n",
        "                flip = iaa.Fliplr(1.0)\n",
        "                zoom = iaa.Affine(scale=1.3)\n",
        "                random_brightness = iaa.Multiply((1, 1.3))\n",
        "                rotate = iaa.Affine(rotate=(-25, 25))\n",
        "                \n",
        "                image_aug = flip(image = image)\n",
        "                image_aug = random_brightness(image = image_aug)\n",
        "                image_aug = zoom(image = image_aug)\n",
        "                image_aug = rotate(image = image_aug)\n",
        "                \n",
        "                rgb_img = cv2.cvtColor(image_aug, cv2.COLOR_BGR2RGB)\n",
        "                resized = cv2.resize(rgb_img, (IMG_SIZE, IMG_SIZE))\n",
        "                ImageFrames.append(resized)\n",
        "                \n",
        "            count += 1\n",
        "        else:\n",
        "            break\n",
        "    \n",
        "    vidcap.release()\n",
        "    \n",
        "    return ImageFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eE_rtxrw5N70",
        "outputId": "157c30e6-2824-4bc5-e305-c1d7d33948a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "we have \n",
            "1000 Violence videos \n",
            "1000 NonViolence videos\n",
            "Choosing less videos for memory issue\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 300/300 [03:39<00:00,  1.37it/s]\n",
            "100%|██████████| 300/300 [04:44<00:00,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 11min 5s, sys: 9.85 s, total: 11min 15s\n",
            "Wall time: 8min 31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from tqdm import tqdm\n",
        "\n",
        "VideoDataDir = PROJECT_DIR + '/Real_Life_Violence_Dataset'\n",
        "print('we have \\n{} Violence videos \\n{} NonViolence videos'.format(\n",
        "              len(os.listdir(VideoDataDir + '/Violence')), \n",
        "              len(os.listdir(VideoDataDir + '/NonViolence'))))\n",
        "\n",
        "X_original = []\n",
        "y_original = []\n",
        "\n",
        "print('Choosing less videos for memory issue')\n",
        "CLASSES = [\"NonViolence\", \"Violence\"]\n",
        "\n",
        "\n",
        "for category in os.listdir(VideoDataDir):\n",
        "    path = os.path.join(VideoDataDir, category)\n",
        "    class_num = CLASSES.index(category)\n",
        "    for i, video in enumerate(tqdm(os.listdir(path)[0:300])):\n",
        "        frames = video_to_frames(path + '/' + video)\n",
        "        for j, frame in enumerate(frames):\n",
        "            X_original.append(frame)\n",
        "            y_original.append(class_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfg7KgIY6LGo",
        "outputId": "3fc69b82-e841-4da7-aeea-7a1f5638d65a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_applications\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▌                         | 10 kB 18.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 30 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 40 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 50 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications) (1.19.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications) (1.5.2)\n",
            "Installing collected packages: keras-applications\n",
            "Successfully installed keras-applications-1.0.8\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_applications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBGnD1j675f6",
        "outputId": "a33732b1-81b2-4acd-f34b-6e4f271acc92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11952"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import numpy as np\n",
        "X_original = np.array(X_original).reshape(-1 , IMG_SIZE * IMG_SIZE * 3)\n",
        "y_original = np.array(y_original)\n",
        "len(X_original)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sH69WUd78WK"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "stratified_sample = StratifiedShuffleSplit(n_splits=2, test_size=0.3, random_state=73)\n",
        "\n",
        "for train_index, test_index in stratified_sample.split(X_original, y_original):\n",
        "    X_train, X_test = X_original[train_index], X_original[test_index]\n",
        "    y_train, y_test = y_original[train_index], y_original[test_index]\n",
        "\n",
        "X_train_nn = X_train.reshape(-1, IMG_SIZE, IMG_SIZE, 3) / 255\n",
        "X_test_nn = X_test.reshape(-1, IMG_SIZE, IMG_SIZE, 3) / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNgQ5imE8CFz"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers.core import Dropout,Flatten,Dense\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upIPmJ0_8Dij",
        "outputId": "d20f9cbc-d141-4fba-a9f7-10690e3f39a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n",
            "9420800/9406464 [==============================] - 0s 0us/step\n",
            "Compiling model...\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " Conv1 (Conv2D)                 (None, 64, 64, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " bn_Conv1 (BatchNormalization)  (None, 64, 64, 32)   128         ['Conv1[0][0]']                  \n",
            "                                                                                                  \n",
            " Conv1_relu (ReLU)              (None, 64, 64, 32)   0           ['bn_Conv1[0][0]']               \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise (Depth  (None, 64, 64, 32)  288         ['Conv1_relu[0][0]']             \n",
            " wiseConv2D)                                                                                      \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_BN (Ba  (None, 64, 64, 32)  128         ['expanded_conv_depthwise[0][0]']\n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_relu (  (None, 64, 64, 32)  0           ['expanded_conv_depthwise_BN[0][0\n",
            " ReLU)                                                           ]']                              \n",
            "                                                                                                  \n",
            " expanded_conv_project (Conv2D)  (None, 64, 64, 16)  512         ['expanded_conv_depthwise_relu[0]\n",
            "                                                                 [0]']                            \n",
            "                                                                                                  \n",
            " expanded_conv_project_BN (Batc  (None, 64, 64, 16)  64          ['expanded_conv_project[0][0]']  \n",
            " hNormalization)                                                                                  \n",
            "                                                                                                  \n",
            " block_1_expand (Conv2D)        (None, 64, 64, 96)   1536        ['expanded_conv_project_BN[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " block_1_expand_BN (BatchNormal  (None, 64, 64, 96)  384         ['block_1_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_1_expand_relu (ReLU)     (None, 64, 64, 96)   0           ['block_1_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_1_pad (ZeroPadding2D)    (None, 65, 65, 96)   0           ['block_1_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_1_depthwise (DepthwiseCo  (None, 32, 32, 96)  864         ['block_1_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_1_depthwise_BN (BatchNor  (None, 32, 32, 96)  384         ['block_1_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_1_depthwise_relu (ReLU)  (None, 32, 32, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_1_project (Conv2D)       (None, 32, 32, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_1_project_BN (BatchNorma  (None, 32, 32, 24)  96          ['block_1_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_expand (Conv2D)        (None, 32, 32, 144)  3456        ['block_1_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_2_expand_BN (BatchNormal  (None, 32, 32, 144)  576        ['block_2_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_2_expand_relu (ReLU)     (None, 32, 32, 144)  0           ['block_2_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_2_depthwise (DepthwiseCo  (None, 32, 32, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_2_depthwise_BN (BatchNor  (None, 32, 32, 144)  576        ['block_2_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_2_depthwise_relu (ReLU)  (None, 32, 32, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_2_project (Conv2D)       (None, 32, 32, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_2_project_BN (BatchNorma  (None, 32, 32, 24)  96          ['block_2_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_add (Add)              (None, 32, 32, 24)   0           ['block_1_project_BN[0][0]',     \n",
            "                                                                  'block_2_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_3_expand (Conv2D)        (None, 32, 32, 144)  3456        ['block_2_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_3_expand_BN (BatchNormal  (None, 32, 32, 144)  576        ['block_3_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_3_expand_relu (ReLU)     (None, 32, 32, 144)  0           ['block_3_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_3_pad (ZeroPadding2D)    (None, 33, 33, 144)  0           ['block_3_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_3_depthwise (DepthwiseCo  (None, 16, 16, 144)  1296       ['block_3_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_3_depthwise_BN (BatchNor  (None, 16, 16, 144)  576        ['block_3_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_3_depthwise_relu (ReLU)  (None, 16, 16, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_3_project (Conv2D)       (None, 16, 16, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_3_project_BN (BatchNorma  (None, 16, 16, 32)  128         ['block_3_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_expand (Conv2D)        (None, 16, 16, 192)  6144        ['block_3_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_4_expand_BN (BatchNormal  (None, 16, 16, 192)  768        ['block_4_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_4_expand_relu (ReLU)     (None, 16, 16, 192)  0           ['block_4_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_4_depthwise (DepthwiseCo  (None, 16, 16, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_4_depthwise_BN (BatchNor  (None, 16, 16, 192)  768        ['block_4_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_4_depthwise_relu (ReLU)  (None, 16, 16, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_4_project (Conv2D)       (None, 16, 16, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_4_project_BN (BatchNorma  (None, 16, 16, 32)  128         ['block_4_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_add (Add)              (None, 16, 16, 32)   0           ['block_3_project_BN[0][0]',     \n",
            "                                                                  'block_4_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_5_expand (Conv2D)        (None, 16, 16, 192)  6144        ['block_4_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_5_expand_BN (BatchNormal  (None, 16, 16, 192)  768        ['block_5_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_5_expand_relu (ReLU)     (None, 16, 16, 192)  0           ['block_5_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_5_depthwise (DepthwiseCo  (None, 16, 16, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_5_depthwise_BN (BatchNor  (None, 16, 16, 192)  768        ['block_5_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_5_depthwise_relu (ReLU)  (None, 16, 16, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_5_project (Conv2D)       (None, 16, 16, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_5_project_BN (BatchNorma  (None, 16, 16, 32)  128         ['block_5_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_5_add (Add)              (None, 16, 16, 32)   0           ['block_4_add[0][0]',            \n",
            "                                                                  'block_5_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_6_expand (Conv2D)        (None, 16, 16, 192)  6144        ['block_5_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_6_expand_BN (BatchNormal  (None, 16, 16, 192)  768        ['block_6_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_6_expand_relu (ReLU)     (None, 16, 16, 192)  0           ['block_6_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_6_pad (ZeroPadding2D)    (None, 17, 17, 192)  0           ['block_6_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_6_depthwise (DepthwiseCo  (None, 8, 8, 192)   1728        ['block_6_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_6_depthwise_BN (BatchNor  (None, 8, 8, 192)   768         ['block_6_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_6_depthwise_relu (ReLU)  (None, 8, 8, 192)    0           ['block_6_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_6_project (Conv2D)       (None, 8, 8, 64)     12288       ['block_6_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_6_project_BN (BatchNorma  (None, 8, 8, 64)    256         ['block_6_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_expand (Conv2D)        (None, 8, 8, 384)    24576       ['block_6_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_7_expand_BN (BatchNormal  (None, 8, 8, 384)   1536        ['block_7_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_7_expand_relu (ReLU)     (None, 8, 8, 384)    0           ['block_7_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_7_depthwise (DepthwiseCo  (None, 8, 8, 384)   3456        ['block_7_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_7_depthwise_BN (BatchNor  (None, 8, 8, 384)   1536        ['block_7_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_7_depthwise_relu (ReLU)  (None, 8, 8, 384)    0           ['block_7_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_7_project (Conv2D)       (None, 8, 8, 64)     24576       ['block_7_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_7_project_BN (BatchNorma  (None, 8, 8, 64)    256         ['block_7_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_add (Add)              (None, 8, 8, 64)     0           ['block_6_project_BN[0][0]',     \n",
            "                                                                  'block_7_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_8_expand (Conv2D)        (None, 8, 8, 384)    24576       ['block_7_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_8_expand_BN (BatchNormal  (None, 8, 8, 384)   1536        ['block_8_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_8_expand_relu (ReLU)     (None, 8, 8, 384)    0           ['block_8_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_8_depthwise (DepthwiseCo  (None, 8, 8, 384)   3456        ['block_8_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_8_depthwise_BN (BatchNor  (None, 8, 8, 384)   1536        ['block_8_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_8_depthwise_relu (ReLU)  (None, 8, 8, 384)    0           ['block_8_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_8_project (Conv2D)       (None, 8, 8, 64)     24576       ['block_8_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_8_project_BN (BatchNorma  (None, 8, 8, 64)    256         ['block_8_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_8_add (Add)              (None, 8, 8, 64)     0           ['block_7_add[0][0]',            \n",
            "                                                                  'block_8_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_9_expand (Conv2D)        (None, 8, 8, 384)    24576       ['block_8_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_9_expand_BN (BatchNormal  (None, 8, 8, 384)   1536        ['block_9_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_9_expand_relu (ReLU)     (None, 8, 8, 384)    0           ['block_9_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_9_depthwise (DepthwiseCo  (None, 8, 8, 384)   3456        ['block_9_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_9_depthwise_BN (BatchNor  (None, 8, 8, 384)   1536        ['block_9_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_9_depthwise_relu (ReLU)  (None, 8, 8, 384)    0           ['block_9_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_9_project (Conv2D)       (None, 8, 8, 64)     24576       ['block_9_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_9_project_BN (BatchNorma  (None, 8, 8, 64)    256         ['block_9_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_9_add (Add)              (None, 8, 8, 64)     0           ['block_8_add[0][0]',            \n",
            "                                                                  'block_9_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_10_expand (Conv2D)       (None, 8, 8, 384)    24576       ['block_9_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_10_expand_BN (BatchNorma  (None, 8, 8, 384)   1536        ['block_10_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_10_expand_relu (ReLU)    (None, 8, 8, 384)    0           ['block_10_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_10_depthwise (DepthwiseC  (None, 8, 8, 384)   3456        ['block_10_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_10_depthwise_BN (BatchNo  (None, 8, 8, 384)   1536        ['block_10_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_10_depthwise_relu (ReLU)  (None, 8, 8, 384)   0           ['block_10_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_10_project (Conv2D)      (None, 8, 8, 96)     36864       ['block_10_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_10_project_BN (BatchNorm  (None, 8, 8, 96)    384         ['block_10_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_expand (Conv2D)       (None, 8, 8, 576)    55296       ['block_10_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_11_expand_BN (BatchNorma  (None, 8, 8, 576)   2304        ['block_11_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_11_expand_relu (ReLU)    (None, 8, 8, 576)    0           ['block_11_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_11_depthwise (DepthwiseC  (None, 8, 8, 576)   5184        ['block_11_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_11_depthwise_BN (BatchNo  (None, 8, 8, 576)   2304        ['block_11_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_11_depthwise_relu (ReLU)  (None, 8, 8, 576)   0           ['block_11_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_11_project (Conv2D)      (None, 8, 8, 96)     55296       ['block_11_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_11_project_BN (BatchNorm  (None, 8, 8, 96)    384         ['block_11_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_add (Add)             (None, 8, 8, 96)     0           ['block_10_project_BN[0][0]',    \n",
            "                                                                  'block_11_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_12_expand (Conv2D)       (None, 8, 8, 576)    55296       ['block_11_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_12_expand_BN (BatchNorma  (None, 8, 8, 576)   2304        ['block_12_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_12_expand_relu (ReLU)    (None, 8, 8, 576)    0           ['block_12_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_12_depthwise (DepthwiseC  (None, 8, 8, 576)   5184        ['block_12_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_12_depthwise_BN (BatchNo  (None, 8, 8, 576)   2304        ['block_12_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_12_depthwise_relu (ReLU)  (None, 8, 8, 576)   0           ['block_12_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_12_project (Conv2D)      (None, 8, 8, 96)     55296       ['block_12_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_12_project_BN (BatchNorm  (None, 8, 8, 96)    384         ['block_12_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_12_add (Add)             (None, 8, 8, 96)     0           ['block_11_add[0][0]',           \n",
            "                                                                  'block_12_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_13_expand (Conv2D)       (None, 8, 8, 576)    55296       ['block_12_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_13_expand_BN (BatchNorma  (None, 8, 8, 576)   2304        ['block_13_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_13_expand_relu (ReLU)    (None, 8, 8, 576)    0           ['block_13_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_13_pad (ZeroPadding2D)   (None, 9, 9, 576)    0           ['block_13_expand_relu[0][0]']   \n",
            "                                                                                                  \n",
            " block_13_depthwise (DepthwiseC  (None, 4, 4, 576)   5184        ['block_13_pad[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_13_depthwise_BN (BatchNo  (None, 4, 4, 576)   2304        ['block_13_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_13_depthwise_relu (ReLU)  (None, 4, 4, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_13_project (Conv2D)      (None, 4, 4, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_13_project_BN (BatchNorm  (None, 4, 4, 160)   640         ['block_13_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_expand (Conv2D)       (None, 4, 4, 960)    153600      ['block_13_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_14_expand_BN (BatchNorma  (None, 4, 4, 960)   3840        ['block_14_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_14_expand_relu (ReLU)    (None, 4, 4, 960)    0           ['block_14_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_14_depthwise (DepthwiseC  (None, 4, 4, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_14_depthwise_BN (BatchNo  (None, 4, 4, 960)   3840        ['block_14_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_14_depthwise_relu (ReLU)  (None, 4, 4, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_14_project (Conv2D)      (None, 4, 4, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_14_project_BN (BatchNorm  (None, 4, 4, 160)   640         ['block_14_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_add (Add)             (None, 4, 4, 160)    0           ['block_13_project_BN[0][0]',    \n",
            "                                                                  'block_14_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_15_expand (Conv2D)       (None, 4, 4, 960)    153600      ['block_14_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_15_expand_BN (BatchNorma  (None, 4, 4, 960)   3840        ['block_15_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_15_expand_relu (ReLU)    (None, 4, 4, 960)    0           ['block_15_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_15_depthwise (DepthwiseC  (None, 4, 4, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_15_depthwise_BN (BatchNo  (None, 4, 4, 960)   3840        ['block_15_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_15_depthwise_relu (ReLU)  (None, 4, 4, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_15_project (Conv2D)      (None, 4, 4, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_15_project_BN (BatchNorm  (None, 4, 4, 160)   640         ['block_15_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_15_add (Add)             (None, 4, 4, 160)    0           ['block_14_add[0][0]',           \n",
            "                                                                  'block_15_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_16_expand (Conv2D)       (None, 4, 4, 960)    153600      ['block_15_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_16_expand_BN (BatchNorma  (None, 4, 4, 960)   3840        ['block_16_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_16_expand_relu (ReLU)    (None, 4, 4, 960)    0           ['block_16_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_16_depthwise (DepthwiseC  (None, 4, 4, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_16_depthwise_BN (BatchNo  (None, 4, 4, 960)   3840        ['block_16_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_16_depthwise_relu (ReLU)  (None, 4, 4, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_16_project (Conv2D)      (None, 4, 4, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_16_project_BN (BatchNorm  (None, 4, 4, 320)   1280        ['block_16_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " Conv_1 (Conv2D)                (None, 4, 4, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " Conv_1_bn (BatchNormalization)  (None, 4, 4, 1280)  5120        ['Conv_1[0][0]']                 \n",
            "                                                                                                  \n",
            " out_relu (ReLU)                (None, 4, 4, 1280)   0           ['Conv_1_bn[0][0]']              \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 1280)        0           ['out_relu[0][0]']               \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1)            1281        ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,259,265\n",
            "Trainable params: 1,281\n",
            "Non-trainable params: 2,257,984\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "epochs = 60\n",
        "\n",
        "from keras import regularizers\n",
        "kernel_regularizer = regularizers.l2(0.0001)\n",
        "\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "\n",
        "def load_layers():\n",
        "    input_tensor = Input(shape=(IMG_SIZE, IMG_SIZE, ColorChannels))\n",
        "    baseModel = MobileNetV2(pooling='avg',\n",
        "                            include_top=False, \n",
        "                            input_tensor=input_tensor)\n",
        "    \n",
        "    headModel = baseModel.output   \n",
        "    headModel = Dense(1, activation=\"sigmoid\")(headModel)\n",
        "    model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "\n",
        "    for layer in baseModel.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    print(\"Compiling model...\")\n",
        "    model.compile(loss=\"binary_crossentropy\",\n",
        "                    optimizer='adam',\n",
        "                    metrics=[\"accuracy\"])\n",
        "\n",
        "    return model\n",
        "\n",
        "if TPU_INIT:\n",
        "    with tpu_strategy.scope():\n",
        "        model = load_layers()\n",
        "else:\n",
        "    model = load_layers()\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-16rQIDQJ0iL"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sByxQgQ8YId"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "patience = 3\n",
        "\n",
        "start_lr = 0.00001\n",
        "min_lr = 0.00001\n",
        "max_lr = 0.00005\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "if TPU_INIT:\n",
        "    max_lr = max_lr * tpu_strategy.num_replicas_in_sync\n",
        "    batch_size = batch_size * tpu_strategy.num_replicas_in_sync\n",
        "\n",
        "rampup_epochs = 5\n",
        "sustain_epochs = 0\n",
        "exp_decay = .8\n",
        "\n",
        "def lrfn(epoch):\n",
        "    if epoch < rampup_epochs:\n",
        "        return (max_lr - start_lr)/rampup_epochs * epoch + start_lr\n",
        "    elif epoch < rampup_epochs + sustain_epochs:\n",
        "        return max_lr\n",
        "    else:\n",
        "        return (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n",
        "\n",
        "\n",
        "class myCallback(Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if ((logs.get('accuracy')>=0.999)):\n",
        "            print(\"\\nLimits Reached cancelling training!\")\n",
        "            self.model.stop_training = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmrgkVpi8Z-L"
      },
      "outputs": [],
      "source": [
        "end_callback = myCallback()\n",
        "\n",
        "lr_callback = LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=False)\n",
        "\n",
        "early_stopping = EarlyStopping(patience = patience, monitor='val_loss',\n",
        "                                 mode='min', restore_best_weights=True, \n",
        "                                 verbose = 1, min_delta = .00075)\n",
        "\n",
        "PROJECT_DIR = MyDrive + '/Violence_Detection'\n",
        "\n",
        "lr_plat = ReduceLROnPlateau(patience = 2, mode = 'min')\n",
        "\n",
        "os.system('rm -rf ./logs/')\n",
        "\n",
        "import datetime\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = TensorBoard(log_dir = log_dir, write_graph=True, histogram_freq=1)\n",
        "\n",
        "checkpoint_filepath = 'ModelWeights.h5'\n",
        "\n",
        "model_checkpoints = ModelCheckpoint(filepath=checkpoint_filepath,\n",
        "                                        save_weights_only=True,\n",
        "                                        monitor='val_loss',\n",
        "                                        mode='min',\n",
        "                                        verbose = 1,\n",
        "                                        save_best_only=True)\n",
        "\n",
        "\n",
        "callbacks = [end_callback, lr_callback, model_checkpoints, tensorboard_callback, early_stopping, lr_plat]\n",
        "\n",
        "if TPU_INIT:\n",
        "    callbacks = [end_callback, lr_callback, model_checkpoints, early_stopping, lr_plat]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2WxIzIm8c76",
        "outputId": "a7280375-2e82-497d-c673-24d3742c2779"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training head...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "2092/2092 [==============================] - ETA: 0s - loss: 0.6906 - accuracy: 0.6174\n",
            "Epoch 00001: val_loss improved from inf to 0.59562, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 150s 70ms/step - loss: 0.6906 - accuracy: 0.6174 - val_loss: 0.5956 - val_accuracy: 0.6776 - lr: 1.0000e-05\n",
            "Epoch 2/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.4837 - accuracy: 0.7720\n",
            "Epoch 00002: val_loss improved from 0.59562 to 0.41251, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 145s 69ms/step - loss: 0.4837 - accuracy: 0.7719 - val_loss: 0.4125 - val_accuracy: 0.8160 - lr: 1.8000e-05\n",
            "Epoch 3/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.3514 - accuracy: 0.8586\n",
            "Epoch 00003: val_loss improved from 0.41251 to 0.30962, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 144s 69ms/step - loss: 0.3514 - accuracy: 0.8586 - val_loss: 0.3096 - val_accuracy: 0.8804 - lr: 2.6000e-05\n",
            "Epoch 4/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.2748 - accuracy: 0.8954\n",
            "Epoch 00004: val_loss improved from 0.30962 to 0.25118, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 144s 69ms/step - loss: 0.2748 - accuracy: 0.8954 - val_loss: 0.2512 - val_accuracy: 0.9055 - lr: 3.4000e-05\n",
            "Epoch 5/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.2276 - accuracy: 0.9171\n",
            "Epoch 00005: val_loss improved from 0.25118 to 0.21528, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 144s 69ms/step - loss: 0.2276 - accuracy: 0.9172 - val_loss: 0.2153 - val_accuracy: 0.9197 - lr: 4.2000e-05\n",
            "Epoch 6/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1965 - accuracy: 0.9303\n",
            "Epoch 00006: val_loss improved from 0.21528 to 0.18914, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 144s 69ms/step - loss: 0.1968 - accuracy: 0.9302 - val_loss: 0.1891 - val_accuracy: 0.9342 - lr: 5.0000e-05\n",
            "Epoch 7/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1762 - accuracy: 0.9363\n",
            "Epoch 00007: val_loss improved from 0.18914 to 0.17575, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 144s 69ms/step - loss: 0.1762 - accuracy: 0.9363 - val_loss: 0.1758 - val_accuracy: 0.9381 - lr: 4.2000e-05\n",
            "Epoch 8/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1639 - accuracy: 0.9412\n",
            "Epoch 00008: val_loss improved from 0.17575 to 0.16732, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 143s 68ms/step - loss: 0.1639 - accuracy: 0.9412 - val_loss: 0.1673 - val_accuracy: 0.9398 - lr: 3.5600e-05\n",
            "Epoch 9/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1552 - accuracy: 0.9458\n",
            "Epoch 00009: val_loss improved from 0.16732 to 0.16194, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 145s 69ms/step - loss: 0.1552 - accuracy: 0.9459 - val_loss: 0.1619 - val_accuracy: 0.9428 - lr: 3.0480e-05\n",
            "Epoch 10/60\n",
            "2092/2092 [==============================] - ETA: 0s - loss: 0.1490 - accuracy: 0.9474\n",
            "Epoch 00010: val_loss improved from 0.16194 to 0.15671, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 144s 69ms/step - loss: 0.1490 - accuracy: 0.9474 - val_loss: 0.1567 - val_accuracy: 0.9437 - lr: 2.6384e-05\n",
            "Epoch 11/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1440 - accuracy: 0.9503\n",
            "Epoch 00011: val_loss improved from 0.15671 to 0.15363, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 142s 68ms/step - loss: 0.1441 - accuracy: 0.9502 - val_loss: 0.1536 - val_accuracy: 0.9462 - lr: 2.3107e-05\n",
            "Epoch 12/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1403 - accuracy: 0.9515\n",
            "Epoch 00012: val_loss improved from 0.15363 to 0.15056, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 143s 68ms/step - loss: 0.1403 - accuracy: 0.9515 - val_loss: 0.1506 - val_accuracy: 0.9473 - lr: 2.0486e-05\n",
            "Epoch 13/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1371 - accuracy: 0.9534\n",
            "Epoch 00013: val_loss improved from 0.15056 to 0.14842, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 142s 68ms/step - loss: 0.1372 - accuracy: 0.9533 - val_loss: 0.1484 - val_accuracy: 0.9487 - lr: 1.8389e-05\n",
            "Epoch 14/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1345 - accuracy: 0.9546\n",
            "Epoch 00014: val_loss improved from 0.14842 to 0.14670, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 145s 69ms/step - loss: 0.1345 - accuracy: 0.9546 - val_loss: 0.1467 - val_accuracy: 0.9481 - lr: 1.6711e-05\n",
            "Epoch 15/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1322 - accuracy: 0.9558\n",
            "Epoch 00015: val_loss improved from 0.14670 to 0.14558, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 144s 69ms/step - loss: 0.1322 - accuracy: 0.9558 - val_loss: 0.1456 - val_accuracy: 0.9501 - lr: 1.5369e-05\n",
            "Epoch 16/60\n",
            "2092/2092 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.9559\n",
            "Epoch 00016: val_loss improved from 0.14558 to 0.14344, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 145s 70ms/step - loss: 0.1303 - accuracy: 0.9559 - val_loss: 0.1434 - val_accuracy: 0.9509 - lr: 1.4295e-05\n",
            "Epoch 17/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1286 - accuracy: 0.9571\n",
            "Epoch 00017: val_loss improved from 0.14344 to 0.14203, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 144s 69ms/step - loss: 0.1286 - accuracy: 0.9571 - val_loss: 0.1420 - val_accuracy: 0.9515 - lr: 1.3436e-05\n",
            "Epoch 18/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1270 - accuracy: 0.9574\n",
            "Epoch 00018: val_loss improved from 0.14203 to 0.14090, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 145s 69ms/step - loss: 0.1270 - accuracy: 0.9574 - val_loss: 0.1409 - val_accuracy: 0.9523 - lr: 1.2749e-05\n",
            "Epoch 19/60\n",
            "2092/2092 [==============================] - ETA: 0s - loss: 0.1256 - accuracy: 0.9589\n",
            "Epoch 00019: val_loss improved from 0.14090 to 0.13992, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 143s 68ms/step - loss: 0.1256 - accuracy: 0.9589 - val_loss: 0.1399 - val_accuracy: 0.9526 - lr: 1.2199e-05\n",
            "Epoch 20/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1243 - accuracy: 0.9586\n",
            "Epoch 00020: val_loss improved from 0.13992 to 0.13888, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 143s 68ms/step - loss: 0.1243 - accuracy: 0.9586 - val_loss: 0.1389 - val_accuracy: 0.9529 - lr: 1.1759e-05\n",
            "Epoch 21/60\n",
            "2092/2092 [==============================] - ETA: 0s - loss: 0.1230 - accuracy: 0.9598\n",
            "Epoch 00021: val_loss improved from 0.13888 to 0.13789, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 146s 70ms/step - loss: 0.1230 - accuracy: 0.9598 - val_loss: 0.1379 - val_accuracy: 0.9532 - lr: 1.1407e-05\n",
            "Epoch 22/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1219 - accuracy: 0.9597\n",
            "Epoch 00022: val_loss improved from 0.13789 to 0.13702, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 145s 69ms/step - loss: 0.1219 - accuracy: 0.9597 - val_loss: 0.1370 - val_accuracy: 0.9532 - lr: 1.1126e-05\n",
            "Epoch 23/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1207 - accuracy: 0.9601\n",
            "Epoch 00023: val_loss improved from 0.13702 to 0.13629, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 145s 69ms/step - loss: 0.1207 - accuracy: 0.9601 - val_loss: 0.1363 - val_accuracy: 0.9532 - lr: 1.0901e-05\n",
            "Epoch 24/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1198 - accuracy: 0.9604\n",
            "Epoch 00024: val_loss improved from 0.13629 to 0.13550, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 145s 69ms/step - loss: 0.1197 - accuracy: 0.9604 - val_loss: 0.1355 - val_accuracy: 0.9540 - lr: 1.0721e-05\n",
            "Epoch 25/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1187 - accuracy: 0.9615\n",
            "Epoch 00025: val_loss improved from 0.13550 to 0.13486, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 143s 68ms/step - loss: 0.1187 - accuracy: 0.9615 - val_loss: 0.1349 - val_accuracy: 0.9543 - lr: 1.0576e-05\n",
            "Epoch 26/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1178 - accuracy: 0.9615\n",
            "Epoch 00026: val_loss improved from 0.13486 to 0.13398, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 145s 69ms/step - loss: 0.1178 - accuracy: 0.9615 - val_loss: 0.1340 - val_accuracy: 0.9543 - lr: 1.0461e-05\n",
            "Epoch 27/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1169 - accuracy: 0.9621\n",
            "Epoch 00027: val_loss improved from 0.13398 to 0.13326, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 144s 69ms/step - loss: 0.1168 - accuracy: 0.9621 - val_loss: 0.1333 - val_accuracy: 0.9545 - lr: 1.0369e-05\n",
            "Epoch 28/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1160 - accuracy: 0.9629\n",
            "Epoch 00028: val_loss improved from 0.13326 to 0.13273, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 145s 69ms/step - loss: 0.1160 - accuracy: 0.9629 - val_loss: 0.1327 - val_accuracy: 0.9545 - lr: 1.0295e-05\n",
            "Epoch 29/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1149 - accuracy: 0.9635\n",
            "Epoch 00029: val_loss improved from 0.13273 to 0.13196, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 144s 69ms/step - loss: 0.1151 - accuracy: 0.9634 - val_loss: 0.1320 - val_accuracy: 0.9548 - lr: 1.0236e-05\n",
            "Epoch 30/60\n",
            "2092/2092 [==============================] - ETA: 0s - loss: 0.1143 - accuracy: 0.9635\n",
            "Epoch 00030: val_loss improved from 0.13196 to 0.13145, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 143s 69ms/step - loss: 0.1143 - accuracy: 0.9635 - val_loss: 0.1314 - val_accuracy: 0.9548 - lr: 1.0189e-05\n",
            "Epoch 31/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1134 - accuracy: 0.9638\n",
            "Epoch 00031: val_loss improved from 0.13145 to 0.13078, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 153s 73ms/step - loss: 0.1134 - accuracy: 0.9638 - val_loss: 0.1308 - val_accuracy: 0.9545 - lr: 1.0151e-05\n",
            "Epoch 32/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1127 - accuracy: 0.9643\n",
            "Epoch 00032: val_loss improved from 0.13078 to 0.13040, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 154s 74ms/step - loss: 0.1127 - accuracy: 0.9643 - val_loss: 0.1304 - val_accuracy: 0.9554 - lr: 1.0121e-05\n",
            "Epoch 33/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1118 - accuracy: 0.9645\n",
            "Epoch 00033: val_loss improved from 0.13040 to 0.12975, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 151s 72ms/step - loss: 0.1118 - accuracy: 0.9645 - val_loss: 0.1297 - val_accuracy: 0.9554 - lr: 1.0097e-05\n",
            "Epoch 34/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1112 - accuracy: 0.9651\n",
            "Epoch 00034: val_loss improved from 0.12975 to 0.12912, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 146s 70ms/step - loss: 0.1112 - accuracy: 0.9651 - val_loss: 0.1291 - val_accuracy: 0.9554 - lr: 1.0077e-05\n",
            "Epoch 35/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1104 - accuracy: 0.9651\n",
            "Epoch 00035: val_loss improved from 0.12912 to 0.12861, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 145s 69ms/step - loss: 0.1104 - accuracy: 0.9651 - val_loss: 0.1286 - val_accuracy: 0.9554 - lr: 1.0062e-05\n",
            "Epoch 36/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1097 - accuracy: 0.9648\n",
            "Epoch 00036: val_loss improved from 0.12861 to 0.12805, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 143s 68ms/step - loss: 0.1097 - accuracy: 0.9649 - val_loss: 0.1281 - val_accuracy: 0.9554 - lr: 1.0050e-05\n",
            "Epoch 37/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1089 - accuracy: 0.9648\n",
            "Epoch 00037: val_loss improved from 0.12805 to 0.12770, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 144s 69ms/step - loss: 0.1089 - accuracy: 0.9649 - val_loss: 0.1277 - val_accuracy: 0.9562 - lr: 1.0040e-05\n",
            "Epoch 38/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1084 - accuracy: 0.9660\n",
            "Epoch 00038: val_loss improved from 0.12770 to 0.12743, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 143s 68ms/step - loss: 0.1084 - accuracy: 0.9661 - val_loss: 0.1274 - val_accuracy: 0.9568 - lr: 1.0032e-05\n",
            "Epoch 39/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1077 - accuracy: 0.9657\n",
            "Epoch 00039: val_loss improved from 0.12743 to 0.12677, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 145s 69ms/step - loss: 0.1077 - accuracy: 0.9657 - val_loss: 0.1268 - val_accuracy: 0.9562 - lr: 1.0025e-05\n",
            "Epoch 40/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1070 - accuracy: 0.9666\n",
            "Epoch 00040: val_loss improved from 0.12677 to 0.12628, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 143s 68ms/step - loss: 0.1070 - accuracy: 0.9667 - val_loss: 0.1263 - val_accuracy: 0.9568 - lr: 1.0020e-05\n",
            "Epoch 41/60\n",
            "2092/2092 [==============================] - ETA: 0s - loss: 0.1063 - accuracy: 0.9662\n",
            "Epoch 00041: val_loss improved from 0.12628 to 0.12562, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 146s 70ms/step - loss: 0.1063 - accuracy: 0.9662 - val_loss: 0.1256 - val_accuracy: 0.9562 - lr: 1.0016e-05\n",
            "Epoch 42/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1057 - accuracy: 0.9664\n",
            "Epoch 00042: val_loss improved from 0.12562 to 0.12534, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 144s 69ms/step - loss: 0.1057 - accuracy: 0.9664 - val_loss: 0.1253 - val_accuracy: 0.9568 - lr: 1.0013e-05\n",
            "Epoch 43/60\n",
            "2092/2092 [==============================] - ETA: 0s - loss: 0.1050 - accuracy: 0.9667\n",
            "Epoch 00043: val_loss improved from 0.12534 to 0.12500, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 144s 69ms/step - loss: 0.1050 - accuracy: 0.9667 - val_loss: 0.1250 - val_accuracy: 0.9571 - lr: 1.0010e-05\n",
            "Epoch 44/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1045 - accuracy: 0.9670\n",
            "Epoch 00044: val_loss improved from 0.12500 to 0.12457, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 146s 70ms/step - loss: 0.1045 - accuracy: 0.9670 - val_loss: 0.1246 - val_accuracy: 0.9573 - lr: 1.0008e-05\n",
            "Epoch 45/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1039 - accuracy: 0.9671\n",
            "Epoch 00045: val_loss improved from 0.12457 to 0.12401, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 144s 69ms/step - loss: 0.1039 - accuracy: 0.9671 - val_loss: 0.1240 - val_accuracy: 0.9571 - lr: 1.0007e-05\n",
            "Epoch 46/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1033 - accuracy: 0.9674\n",
            "Epoch 00046: val_loss improved from 0.12401 to 0.12347, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 146s 70ms/step - loss: 0.1033 - accuracy: 0.9674 - val_loss: 0.1235 - val_accuracy: 0.9568 - lr: 1.0005e-05\n",
            "Epoch 47/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1028 - accuracy: 0.9680\n",
            "Epoch 00047: val_loss improved from 0.12347 to 0.12323, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 146s 70ms/step - loss: 0.1028 - accuracy: 0.9680 - val_loss: 0.1232 - val_accuracy: 0.9573 - lr: 1.0004e-05\n",
            "Epoch 48/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1022 - accuracy: 0.9676\n",
            "Epoch 00048: val_loss improved from 0.12323 to 0.12268, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 144s 69ms/step - loss: 0.1022 - accuracy: 0.9676 - val_loss: 0.1227 - val_accuracy: 0.9571 - lr: 1.0003e-05\n",
            "Epoch 49/60\n",
            "2092/2092 [==============================] - ETA: 0s - loss: 0.1016 - accuracy: 0.9682\n",
            "Epoch 00049: val_loss improved from 0.12268 to 0.12255, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 144s 69ms/step - loss: 0.1016 - accuracy: 0.9682 - val_loss: 0.1225 - val_accuracy: 0.9582 - lr: 1.0003e-05\n",
            "Epoch 50/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1011 - accuracy: 0.9684\n",
            "Epoch 00050: val_loss improved from 0.12255 to 0.12193, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 146s 70ms/step - loss: 0.1011 - accuracy: 0.9684 - val_loss: 0.1219 - val_accuracy: 0.9576 - lr: 1.0002e-05\n",
            "Epoch 51/60\n",
            "2092/2092 [==============================] - ETA: 0s - loss: 0.1005 - accuracy: 0.9683\n",
            "Epoch 00051: val_loss improved from 0.12193 to 0.12151, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 146s 70ms/step - loss: 0.1005 - accuracy: 0.9683 - val_loss: 0.1215 - val_accuracy: 0.9573 - lr: 1.0002e-05\n",
            "Epoch 52/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.1000 - accuracy: 0.9686\n",
            "Epoch 00052: val_loss improved from 0.12151 to 0.12116, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 144s 69ms/step - loss: 0.1000 - accuracy: 0.9686 - val_loss: 0.1212 - val_accuracy: 0.9576 - lr: 1.0001e-05\n",
            "Epoch 53/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.0995 - accuracy: 0.9687\n",
            "Epoch 00053: val_loss improved from 0.12116 to 0.12090, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 146s 70ms/step - loss: 0.0994 - accuracy: 0.9687 - val_loss: 0.1209 - val_accuracy: 0.9582 - lr: 1.0001e-05\n",
            "Epoch 54/60\n",
            "2092/2092 [==============================] - ETA: 0s - loss: 0.0989 - accuracy: 0.9686\n",
            "Epoch 00054: val_loss improved from 0.12090 to 0.12065, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 147s 70ms/step - loss: 0.0989 - accuracy: 0.9686 - val_loss: 0.1206 - val_accuracy: 0.9582 - lr: 1.0001e-05\n",
            "Epoch 55/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.0985 - accuracy: 0.9688\n",
            "Epoch 00055: val_loss improved from 0.12065 to 0.12010, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 147s 70ms/step - loss: 0.0985 - accuracy: 0.9688 - val_loss: 0.1201 - val_accuracy: 0.9582 - lr: 1.0001e-05\n",
            "Epoch 56/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.0980 - accuracy: 0.9693\n",
            "Epoch 00056: val_loss improved from 0.12010 to 0.11978, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 147s 70ms/step - loss: 0.0980 - accuracy: 0.9693 - val_loss: 0.1198 - val_accuracy: 0.9590 - lr: 1.0001e-05\n",
            "Epoch 57/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.0975 - accuracy: 0.9689\n",
            "Epoch 00057: val_loss improved from 0.11978 to 0.11952, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 147s 71ms/step - loss: 0.0975 - accuracy: 0.9689 - val_loss: 0.1195 - val_accuracy: 0.9590 - lr: 1.0000e-05\n",
            "Epoch 58/60\n",
            "2091/2092 [============================>.] - ETA: 0s - loss: 0.0970 - accuracy: 0.9688\n",
            "Epoch 00058: val_loss improved from 0.11952 to 0.11926, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 146s 70ms/step - loss: 0.0970 - accuracy: 0.9688 - val_loss: 0.1193 - val_accuracy: 0.9596 - lr: 1.0000e-05\n",
            "Epoch 59/60\n",
            "2092/2092 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 0.9688\n",
            "Epoch 00059: val_loss improved from 0.11926 to 0.11882, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 148s 71ms/step - loss: 0.0965 - accuracy: 0.9688 - val_loss: 0.1188 - val_accuracy: 0.9590 - lr: 1.0000e-05\n",
            "Epoch 60/60\n",
            "2092/2092 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 0.9693\n",
            "Epoch 00060: val_loss improved from 0.11882 to 0.11862, saving model to ModelWeights.h5\n",
            "2092/2092 [==============================] - 147s 70ms/step - loss: 0.0960 - accuracy: 0.9693 - val_loss: 0.1186 - val_accuracy: 0.9596 - lr: 1.0000e-05\n",
            "\n",
            "Restoring best Weights for MobileNetV2\n"
          ]
        }
      ],
      "source": [
        "print('Training head...')\n",
        "#model.load_weights('./Model_Weights.h5')\n",
        "\n",
        "history = model.fit(X_train_nn ,y_train, epochs=epochs,\n",
        "                        callbacks=callbacks,\n",
        "                        validation_data = (X_test_nn, y_test),\n",
        "                        batch_size=batch_size)\n",
        "\n",
        "print('\\nRestoring best Weights for MobileNetV2')\n",
        "model.load_weights(checkpoint_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuiQb3JkDyQL"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "def print_graph(item, index, history):\n",
        "    plt.figure()\n",
        "    train_values = history.history[item][0:index]\n",
        "    plt.plot(train_values)\n",
        "    test_values = history.history['val_' + item][0:index]\n",
        "    plt.plot(test_values)\n",
        "    plt.legend(['training','validation'])\n",
        "    plt.title('Training and validation '+ item)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.show()\n",
        "    plot = '{}.png'.format(item)\n",
        "    plt.savefig(plot)\n",
        "\n",
        "\n",
        "def get_best_epoch(test_loss, history):\n",
        "    for key, item in enumerate(history.history.items()):\n",
        "        (name, arr) = item\n",
        "        if name == 'val_loss':\n",
        "            for i in range(len(arr)):\n",
        "                if round(test_loss, 2) == round(arr[i], 2):\n",
        "                    return i\n",
        "                \n",
        "def model_summary(model, history):\n",
        "    print('---'*30)\n",
        "    test_loss, test_accuracy = model.evaluate(X_test_nn, y_test, verbose=0)\n",
        "\n",
        "    if history:\n",
        "        index = get_best_epoch(test_loss, history)\n",
        "        print('Best Epochs: ', index)\n",
        "\n",
        "        train_accuracy = history.history['accuracy'][index]\n",
        "        train_loss = history.history['loss'][index]\n",
        "\n",
        "        print('Accuracy on train:',train_accuracy,'\\tLoss on train:',train_loss)\n",
        "        print('Accuracy on test:',test_accuracy,'\\tLoss on test:',test_loss)\n",
        "        print_graph('loss', index, history)\n",
        "        print_graph('accuracy', index, history)\n",
        "        print('---'*30)     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "Tgwe-XxaD2Rj",
        "outputId": "a0fd9200-3258-4959-f463-4722604439d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------------------------\n",
            "Best Epochs:  42\n",
            "Accuracy on train: 0.9666507244110107 \tLoss on train: 0.10502869635820389\n",
            "Accuracy on test: 0.9595649838447571 \tLoss on test: 0.11861903965473175\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_summary(model, history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_c-c4j_D_Fd",
        "outputId": "f576f2d3-f860-40ee-ede8-795c0662366b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating network...\n"
          ]
        }
      ],
      "source": [
        "# evaluate the network\n",
        "print(\"Evaluating network...\")\n",
        "predictions = model.predict(X_test_nn)\n",
        "preds = predictions > 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "mXTWKIOTEB9T",
        "outputId": "9dae8ee0-0ae5-40d5-92c3-8f0688daefe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Correct Predictions: 3441\n",
            "> Wrong Predictions: 145\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            " NonViolence       0.96      0.95      0.96      1643\n",
            "    Violence       0.96      0.97      0.96      1943\n",
            "\n",
            "    accuracy                           0.96      3586\n",
            "   macro avg       0.96      0.96      0.96      3586\n",
            "weighted avg       0.96      0.96      0.96      3586\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve, roc_auc_score, plot_roc_curve, accuracy_score, classification_report, confusion_matrix\n",
        "corr_pred = metrics.confusion_matrix(y_test, preds)\n",
        "\n",
        "n_correct = np.int((corr_pred[0][0] + corr_pred[1][1]))\n",
        "print('> Correct Predictions:', n_correct)\n",
        "n_wrongs = np.int((corr_pred[0][1] + (corr_pred[1][0])))\n",
        "print('> Wrong Predictions:', n_wrongs)\n",
        "\n",
        "sns.heatmap(corr_pred,annot=True, fmt=\"d\",cmap=\"Blues\")\n",
        "plt.show()\n",
        "\n",
        "print(metrics.classification_report(y_test, preds, \n",
        "                           target_names=[\"NonViolence\", \"Violence\"]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Copy of  Violence Detection with MobileNet V2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}